{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clear import CLEAR1\n",
    "from rslvq import RSLVQ\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.09744  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.7119                0.2654          0.4601   \n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "3             0.6869                0.2575          0.6638   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "567           0.9387                0.2650          0.4087   \n",
       "568           0.0000                0.0000          0.2871   \n",
       "\n",
       "     fractal_dimension_worst  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_c_data = pd.read_csv('data.csv')\n",
    "b_c_data.columns\n",
    "b_c_data.drop(['id', 'Unnamed: 32'], axis = 1, inplace= True)\n",
    "label = b_c_data['diagnosis'].replace({'M': 0, 'B': 1})\n",
    "train_data = b_c_data.drop(['diagnosis'], axis = 1)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scale = MinMaxScaler()\n",
    "X = scale.fit_transform(train_data)\n",
    "norm_t_data = pd.DataFrame(X, columns = train_data.columns, index = train_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "x_train, x_val, y_train, y_val = train_test_split(np.array(norm_t_data), np.array(label), test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = RSLVQ(num_prototypes_per_class=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc.......94.72361809045226, loss......1252.79989771253\n",
      "Acc.......95.22613065326632, loss......1902.2631502190725\n",
      "Acc.......95.7286432160804, loss......2413.8657434386914\n",
      "Acc.......95.97989949748744, loss......2842.0497475190377\n",
      "Acc.......96.23115577889448, loss......3211.700117811515\n",
      "Acc.......96.4824120603015, loss......3536.8757873397817\n",
      "Acc.......96.73366834170855, loss......3826.652595998014\n",
      "Acc.......96.73366834170855, loss......4087.384195366726\n",
      "Acc.......96.98492462311557, loss......4323.762927692385\n",
      "Acc.......96.98492462311557, loss......4539.3900659231185\n",
      "Acc.......96.98492462311557, loss......4737.111046197455\n",
      "Acc.......96.98492462311557, loss......4919.225317315978\n",
      "Acc.......96.98492462311557, loss......5087.6242703414755\n",
      "Acc.......97.23618090452261, loss......5243.885680035959\n",
      "Acc.......97.23618090452261, loss......5389.340704646834\n",
      "Acc.......97.23618090452261, loss......5525.122912792564\n",
      "Acc.......97.23618090452261, loss......5652.205133919199\n",
      "Acc.......97.23618090452261, loss......5771.427798829544\n",
      "Acc.......97.23618090452261, loss......5883.5211614013315\n",
      "Acc.......97.23618090452261, loss......5989.12300683194\n",
      "Acc.......97.23618090452261, loss......6088.792954444332\n",
      "Acc.......97.23618090452261, loss......6183.024140067348\n",
      "Acc.......97.23618090452261, loss......6272.252847779804\n",
      "Acc.......97.23618090452261, loss......6356.86651379961\n",
      "Acc.......97.23618090452261, loss......6437.210422446379\n",
      "Acc.......97.23618090452261, loss......6513.593340486262\n",
      "Acc.......97.23618090452261, loss......6586.29228234103\n",
      "Acc.......97.23618090452261, loss......6655.556558517135\n",
      "Acc.......97.23618090452261, loss......6721.611229172206\n",
      "Acc.......97.23618090452261, loss......6784.6600612901675\n",
      "Acc.......97.48743718592965, loss......6844.888069632054\n",
      "Acc.......97.48743718592965, loss......6902.463707174056\n",
      "Acc.......97.48743718592965, loss......6957.540759213513\n",
      "Acc.......97.48743718592965, loss......7010.259986047789\n",
      "Acc.......97.48743718592965, loss......7060.750551613262\n",
      "Acc.......97.48743718592965, loss......7109.131269340614\n",
      "Acc.......97.48743718592965, loss......7155.511691454452\n",
      "Acc.......97.48743718592965, loss......7199.993063801412\n",
      "Acc.......97.48743718592965, loss......7242.669164861197\n",
      "Acc.......97.48743718592965, loss......7283.627044744823\n",
      "Acc.......97.48743718592965, loss......7322.947677608177\n",
      "Acc.......97.48743718592965, loss......7360.706538920409\n",
      "Acc.......97.48743718592965, loss......7396.974117358277\n",
      "Acc.......97.48743718592965, loss......7431.816369693735\n",
      "Acc.......97.48743718592965, loss......7465.295125856791\n",
      "Acc.......97.48743718592965, loss......7497.4684503536255\n",
      "Acc.......97.48743718592965, loss......7528.390965369639\n",
      "Acc.......97.48743718592965, loss......7558.114140164426\n",
      "Acc.......97.48743718592965, loss......7586.68655074989\n",
      "Acc.......97.48743718592965, loss......7614.154113316632\n",
      "Acc.......97.48743718592965, loss......7640.560294423813\n",
      "Acc.......97.48743718592965, loss......7665.94630058131\n",
      "Acc.......97.48743718592965, loss......7690.351249521407\n",
      "Acc.......97.48743718592965, loss......7713.812325171065\n",
      "Acc.......97.48743718592965, loss......7736.364918089358\n",
      "Acc.......97.48743718592965, loss......7758.042752921119\n",
      "Acc.......97.48743718592965, loss......7778.878004232983\n",
      "Acc.......97.48743718592965, loss......7798.90140193747\n",
      "Acc.......97.48743718592965, loss......7818.142327371021\n",
      "Acc.......97.48743718592965, loss......7836.628900970263\n",
      "Acc.......97.48743718592965, loss......7854.3880623843725\n",
      "Acc.......97.48743718592965, loss......7871.44564376844\n",
      "Acc.......97.48743718592965, loss......7887.826436921179\n",
      "Acc.......97.48743718592965, loss......7903.554254858745\n",
      "Acc.......97.48743718592965, loss......7918.651988353499\n",
      "Acc.......97.48743718592965, loss......7933.141657910784\n",
      "Acc.......97.48743718592965, loss......7947.044461608182\n",
      "Acc.......97.48743718592965, loss......7960.38081917789\n",
      "Acc.......97.48743718592965, loss......7973.170412674814\n",
      "Acc.......97.48743718592965, loss......7985.432224038576\n",
      "Acc.......97.48743718592965, loss......7997.184569827554\n",
      "Acc.......97.48743718592965, loss......8008.4451333758625\n",
      "Acc.......97.48743718592965, loss......8019.230994600153\n",
      "Acc.......97.48743718592965, loss......8029.5586576616915\n",
      "Acc.......97.48743718592965, loss......8039.444076669542\n",
      "Acc.......97.48743718592965, loss......8048.902679593812\n",
      "Acc.......97.48743718592965, loss......8057.94939054216\n",
      "Acc.......97.48743718592965, loss......8066.5986505387355\n",
      "Acc.......97.48743718592965, loss......8074.864436932321\n",
      "Acc.......97.48743718592965, loss......8082.760281549007\n",
      "Acc.......97.48743718592965, loss......8090.299287694384\n",
      "Acc.......97.48743718592965, loss......8097.494146101133\n",
      "Acc.......97.48743718592965, loss......8104.35714990941\n",
      "Acc.......97.48743718592965, loss......8110.900208759633\n",
      "Acc.......97.48743718592965, loss......8117.134862070705\n",
      "Acc.......97.48743718592965, loss......8123.072291570048\n",
      "Acc.......97.48743718592965, loss......8128.723333136339\n",
      "Acc.......97.48743718592965, loss......8134.098488010379\n",
      "Acc.......97.48743718592965, loss......8139.207933425119\n",
      "Acc.......97.48743718592965, loss......8144.061532701024\n",
      "Acc.......97.48743718592965, loss......8148.668844849422\n",
      "Acc.......97.48743718592965, loss......8153.0391337226265\n",
      "Acc.......97.48743718592965, loss......8157.181376746232\n",
      "Acc.......97.48743718592965, loss......8161.104273266168\n",
      "Acc.......97.48743718592965, loss......8164.816252540038\n",
      "Acc.......97.48743718592965, loss......8168.325481399861\n",
      "Acc.......97.48743718592965, loss......8171.639871611008\n",
      "Acc.......97.48743718592965, loss......8174.767086949811\n",
      "Acc.......97.48743718592965, loss......8177.714550020512\n",
      "Acc.......97.48743718592965, loss......8180.489448830345\n"
     ]
    }
   ],
   "source": [
    "prototypes,_ = trained_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.24561403508771"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model.evaluate(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = pd.DataFrame(np.array(label), columns = ['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "malignant_cases = norm_t_data.loc[lab['labels'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     labels\n",
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "..      ...\n",
       "564       0\n",
       "565       0\n",
       "566       0\n",
       "567       0\n",
       "568       1\n",
       "\n",
       "[569 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_explainer = CLEAR1(trained_model, 100,synthetic_generator_scheme = 'Perturbation', classification_threshold = 0.5, number_of_CFEs = 200, wachter_search_max = 300, cat_cols=['area_mean'], set_immutable=['radius_mean', 'texture_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_explainer.fit(norm_t_data, lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\amade\\Documents\\GitHub\\Explainable-AI\\Counterfactual Explanations\\CLEAR\\clear_example_for_lvq_models.ipynb Cell 13\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/amade/Documents/GitHub/Explainable-AI/Counterfactual%20Explanations/CLEAR/clear_example_for_lvq_models.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m a, b \u001b[39m=\u001b[39m new_explainer\u001b[39m.\u001b[39;49msynthetic_generator(norm_t_data, lab,norm_t_data\u001b[39m.\u001b[39;49miloc[\u001b[39m0\u001b[39;49m],\u001b[39m1\u001b[39;49m )\n",
      "File \u001b[1;32mc:\\Users\\amade\\Documents\\GitHub\\Explainable-AI\\Counterfactual Explanations\\CLEAR\\clear.py:312\u001b[0m, in \u001b[0;36mCLEAR1.synthetic_generator\u001b[1;34m(self, train_data, training_labels, unit, target_class)\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(train_data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]):\n\u001b[0;32m    311\u001b[0m         alpha \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 312\u001b[0m         perturbed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mperturb_col(unit, i\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m, target_class, mean\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, std_dev\u001b[39m=\u001b[39;49malpha\u001b[39m*\u001b[39;49m(\u001b[39m0.9\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m(n_runs)))\n\u001b[0;32m    313\u001b[0m         lst\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39marray(perturbed))\n\u001b[0;32m    314\u001b[0m n_runs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\amade\\Documents\\GitHub\\Explainable-AI\\Counterfactual Explanations\\CLEAR\\clear.py:82\u001b[0m, in \u001b[0;36mCLEAR1.perturb_col\u001b[1;34m(self, unit, num_to_perturb, target_class, mean, std_dev)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mperturb_col\u001b[39m(\u001b[39mself\u001b[39m, unit, num_to_perturb, target_class, mean\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, std_dev\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m     81\u001b[0m     counterfactual_class \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_data\u001b[39m.\u001b[39mloc[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_labels[\u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m target_class]\n\u001b[1;32m---> 82\u001b[0m     columns \u001b[39m=\u001b[39m unit\u001b[39m.\u001b[39;49mcolumns\n\u001b[0;32m     83\u001b[0m     perturbed_vector \u001b[39m=\u001b[39m unit\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m     84\u001b[0m     indices_to_perturb \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39msample(\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(perturbed_vector)), num_to_perturb)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\generic.py:5907\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5900\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   5901\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[0;32m   5902\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[0;32m   5903\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[0;32m   5904\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5905\u001b[0m ):\n\u001b[0;32m   5906\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[1;32m-> 5907\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "a, b = new_explainer.synthetic_generator(norm_t_data, lab,norm_t_data.iloc[0],1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.521037</td>\n",
       "      <td>0.022658</td>\n",
       "      <td>0.545989</td>\n",
       "      <td>0.363733</td>\n",
       "      <td>0.593753</td>\n",
       "      <td>0.792037</td>\n",
       "      <td>0.226959</td>\n",
       "      <td>0.731113</td>\n",
       "      <td>0.686364</td>\n",
       "      <td>0.605518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620776</td>\n",
       "      <td>0.141525</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.450698</td>\n",
       "      <td>0.601136</td>\n",
       "      <td>0.619292</td>\n",
       "      <td>0.568610</td>\n",
       "      <td>0.912027</td>\n",
       "      <td>0.598462</td>\n",
       "      <td>0.418864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.521037</td>\n",
       "      <td>0.022658</td>\n",
       "      <td>0.545989</td>\n",
       "      <td>0.363733</td>\n",
       "      <td>0.593753</td>\n",
       "      <td>0.792037</td>\n",
       "      <td>0.703140</td>\n",
       "      <td>0.731113</td>\n",
       "      <td>0.686364</td>\n",
       "      <td>0.605518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620776</td>\n",
       "      <td>0.141525</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.450698</td>\n",
       "      <td>0.601136</td>\n",
       "      <td>0.619292</td>\n",
       "      <td>0.568610</td>\n",
       "      <td>0.912027</td>\n",
       "      <td>0.299067</td>\n",
       "      <td>0.418864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.521037</td>\n",
       "      <td>0.022658</td>\n",
       "      <td>0.545989</td>\n",
       "      <td>0.363733</td>\n",
       "      <td>0.593753</td>\n",
       "      <td>0.792037</td>\n",
       "      <td>0.703140</td>\n",
       "      <td>0.731113</td>\n",
       "      <td>0.686364</td>\n",
       "      <td>0.605518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279254</td>\n",
       "      <td>0.141525</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.450698</td>\n",
       "      <td>0.601136</td>\n",
       "      <td>0.619292</td>\n",
       "      <td>0.568610</td>\n",
       "      <td>0.912027</td>\n",
       "      <td>0.598462</td>\n",
       "      <td>0.418864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.521037</td>\n",
       "      <td>0.022658</td>\n",
       "      <td>0.545989</td>\n",
       "      <td>0.363733</td>\n",
       "      <td>0.593753</td>\n",
       "      <td>0.792037</td>\n",
       "      <td>0.226959</td>\n",
       "      <td>0.731113</td>\n",
       "      <td>0.686364</td>\n",
       "      <td>0.605518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620776</td>\n",
       "      <td>0.141525</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.450698</td>\n",
       "      <td>0.601136</td>\n",
       "      <td>0.619292</td>\n",
       "      <td>0.568610</td>\n",
       "      <td>0.912027</td>\n",
       "      <td>0.598462</td>\n",
       "      <td>0.418864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.521037</td>\n",
       "      <td>0.022658</td>\n",
       "      <td>0.545989</td>\n",
       "      <td>0.363733</td>\n",
       "      <td>0.593753</td>\n",
       "      <td>0.792037</td>\n",
       "      <td>0.703140</td>\n",
       "      <td>0.731113</td>\n",
       "      <td>0.686364</td>\n",
       "      <td>0.605518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620776</td>\n",
       "      <td>0.141525</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.450698</td>\n",
       "      <td>0.601136</td>\n",
       "      <td>0.619292</td>\n",
       "      <td>0.568610</td>\n",
       "      <td>0.912027</td>\n",
       "      <td>0.598462</td>\n",
       "      <td>0.418864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9564</th>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.428813</td>\n",
       "      <td>0.678668</td>\n",
       "      <td>0.566490</td>\n",
       "      <td>0.526948</td>\n",
       "      <td>0.296055</td>\n",
       "      <td>0.571462</td>\n",
       "      <td>0.690358</td>\n",
       "      <td>0.336364</td>\n",
       "      <td>0.132056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623266</td>\n",
       "      <td>0.383262</td>\n",
       "      <td>0.576174</td>\n",
       "      <td>0.452664</td>\n",
       "      <td>0.461137</td>\n",
       "      <td>0.178527</td>\n",
       "      <td>0.328035</td>\n",
       "      <td>0.761512</td>\n",
       "      <td>0.097575</td>\n",
       "      <td>0.105667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9565</th>\n",
       "      <td>0.622320</td>\n",
       "      <td>0.626987</td>\n",
       "      <td>0.604036</td>\n",
       "      <td>0.474019</td>\n",
       "      <td>0.407782</td>\n",
       "      <td>0.257714</td>\n",
       "      <td>0.337395</td>\n",
       "      <td>0.486630</td>\n",
       "      <td>0.349495</td>\n",
       "      <td>0.113100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560655</td>\n",
       "      <td>0.699094</td>\n",
       "      <td>0.520892</td>\n",
       "      <td>0.379915</td>\n",
       "      <td>0.300007</td>\n",
       "      <td>0.159997</td>\n",
       "      <td>0.256789</td>\n",
       "      <td>0.559450</td>\n",
       "      <td>0.198502</td>\n",
       "      <td>0.074315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9566</th>\n",
       "      <td>0.455251</td>\n",
       "      <td>0.621238</td>\n",
       "      <td>0.445788</td>\n",
       "      <td>0.303118</td>\n",
       "      <td>0.288165</td>\n",
       "      <td>0.254340</td>\n",
       "      <td>0.216753</td>\n",
       "      <td>0.263519</td>\n",
       "      <td>0.267677</td>\n",
       "      <td>0.137321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393099</td>\n",
       "      <td>0.589019</td>\n",
       "      <td>0.379949</td>\n",
       "      <td>0.230731</td>\n",
       "      <td>0.282177</td>\n",
       "      <td>0.273705</td>\n",
       "      <td>0.271805</td>\n",
       "      <td>0.487285</td>\n",
       "      <td>0.128721</td>\n",
       "      <td>0.151909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9567</th>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.663510</td>\n",
       "      <td>0.665538</td>\n",
       "      <td>0.475716</td>\n",
       "      <td>0.588336</td>\n",
       "      <td>0.790197</td>\n",
       "      <td>0.823336</td>\n",
       "      <td>0.755467</td>\n",
       "      <td>0.675253</td>\n",
       "      <td>0.425442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.633582</td>\n",
       "      <td>0.730277</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.402035</td>\n",
       "      <td>0.619626</td>\n",
       "      <td>0.815758</td>\n",
       "      <td>0.749760</td>\n",
       "      <td>0.910653</td>\n",
       "      <td>0.497142</td>\n",
       "      <td>0.452315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9568</th>\n",
       "      <td>0.036869</td>\n",
       "      <td>0.501522</td>\n",
       "      <td>0.028540</td>\n",
       "      <td>0.015907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266162</td>\n",
       "      <td>0.187026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054287</td>\n",
       "      <td>0.489072</td>\n",
       "      <td>0.043578</td>\n",
       "      <td>0.020497</td>\n",
       "      <td>0.124084</td>\n",
       "      <td>0.036043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257441</td>\n",
       "      <td>0.100682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0        0.521037      0.022658        0.545989   0.363733         0.593753   \n",
       "1        0.521037      0.022658        0.545989   0.363733         0.593753   \n",
       "2        0.521037      0.022658        0.545989   0.363733         0.593753   \n",
       "3        0.521037      0.022658        0.545989   0.363733         0.593753   \n",
       "4        0.521037      0.022658        0.545989   0.363733         0.593753   \n",
       "...           ...           ...             ...        ...              ...   \n",
       "9564     0.690000      0.428813        0.678668   0.566490         0.526948   \n",
       "9565     0.622320      0.626987        0.604036   0.474019         0.407782   \n",
       "9566     0.455251      0.621238        0.445788   0.303118         0.288165   \n",
       "9567     0.644564      0.663510        0.665538   0.475716         0.588336   \n",
       "9568     0.036869      0.501522        0.028540   0.015907         0.000000   \n",
       "\n",
       "      compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0             0.792037        0.226959             0.731113       0.686364   \n",
       "1             0.792037        0.703140             0.731113       0.686364   \n",
       "2             0.792037        0.703140             0.731113       0.686364   \n",
       "3             0.792037        0.226959             0.731113       0.686364   \n",
       "4             0.792037        0.703140             0.731113       0.686364   \n",
       "...                ...             ...                  ...            ...   \n",
       "9564          0.296055        0.571462             0.690358       0.336364   \n",
       "9565          0.257714        0.337395             0.486630       0.349495   \n",
       "9566          0.254340        0.216753             0.263519       0.267677   \n",
       "9567          0.790197        0.823336             0.755467       0.675253   \n",
       "9568          0.074351        0.000000             0.000000       0.266162   \n",
       "\n",
       "      fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
       "0                   0.605518  ...      0.620776       0.141525   \n",
       "1                   0.605518  ...      0.620776       0.141525   \n",
       "2                   0.605518  ...      0.279254       0.141525   \n",
       "3                   0.605518  ...      0.620776       0.141525   \n",
       "4                   0.605518  ...      0.620776       0.141525   \n",
       "...                      ...  ...           ...            ...   \n",
       "9564                0.132056  ...      0.623266       0.383262   \n",
       "9565                0.113100  ...      0.560655       0.699094   \n",
       "9566                0.137321  ...      0.393099       0.589019   \n",
       "9567                0.425442  ...      0.633582       0.730277   \n",
       "9568                0.187026  ...      0.054287       0.489072   \n",
       "\n",
       "      perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "0            0.668310    0.450698          0.601136           0.619292   \n",
       "1            0.668310    0.450698          0.601136           0.619292   \n",
       "2            0.668310    0.450698          0.601136           0.619292   \n",
       "3            0.668310    0.450698          0.601136           0.619292   \n",
       "4            0.668310    0.450698          0.601136           0.619292   \n",
       "...               ...         ...               ...                ...   \n",
       "9564         0.576174    0.452664          0.461137           0.178527   \n",
       "9565         0.520892    0.379915          0.300007           0.159997   \n",
       "9566         0.379949    0.230731          0.282177           0.273705   \n",
       "9567         0.668310    0.402035          0.619626           0.815758   \n",
       "9568         0.043578    0.020497          0.124084           0.036043   \n",
       "\n",
       "      concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0            0.568610              0.912027        0.598462   \n",
       "1            0.568610              0.912027        0.299067   \n",
       "2            0.568610              0.912027        0.598462   \n",
       "3            0.568610              0.912027        0.598462   \n",
       "4            0.568610              0.912027        0.598462   \n",
       "...               ...                   ...             ...   \n",
       "9564         0.328035              0.761512        0.097575   \n",
       "9565         0.256789              0.559450        0.198502   \n",
       "9566         0.271805              0.487285        0.128721   \n",
       "9567         0.749760              0.910653        0.497142   \n",
       "9568         0.000000              0.000000        0.257441   \n",
       "\n",
       "      fractal_dimension_worst  \n",
       "0                    0.418864  \n",
       "1                    0.418864  \n",
       "2                    0.418864  \n",
       "3                    0.418864  \n",
       "4                    0.418864  \n",
       "...                       ...  \n",
       "9564                 0.105667  \n",
       "9565                 0.074315  \n",
       "9566                 0.151909  \n",
       "9567                 0.452315  \n",
       "9568                 0.100682  \n",
       "\n",
       "[9569 rows x 30 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels    187\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.iloc[0:899].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9558</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9559</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9560</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9561</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9568</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2256 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels\n",
       "444        1\n",
       "456        1\n",
       "477        1\n",
       "490        1\n",
       "507        1\n",
       "...      ...\n",
       "9558       1\n",
       "9559       1\n",
       "9560       1\n",
       "9561       1\n",
       "9568       1\n",
       "\n",
       "[2256 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.loc[b['labels'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249\n",
      "2386\n",
      "5934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amade\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "new_explainer = CLEAR1(trained_model, 100, neighbourhood= 'balanced', synthetic_generator_scheme = 'Perturbation', classification_threshold = 0.5, number_of_CFEs = 200, wachter_search_max = 300, set_immutable=['radius_mean'])\n",
    "new_explainer.fit(norm_t_data, lab)\n",
    "cf, es_cf = new_explainer.generate_counterfactual(norm_t_data.iloc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "radius_mean                0.601496\n",
       "texture_mean               0.300027\n",
       "perimeter_mean             0.308689\n",
       "area_mean                  0.198232\n",
       "smoothness_mean            0.390648\n",
       "compactness_mean           0.431017\n",
       "concavity_mean             0.178833\n",
       "concave points_mean        0.229393\n",
       "symmetry_mean              0.509596\n",
       "fractal_dimension_mean     0.259729\n",
       "radius_se                  0.229622\n",
       "texture_se                 0.170943\n",
       "perimeter_se               0.082941\n",
       "area_se                    0.162922\n",
       "smoothness_se              0.179275\n",
       "compactness_se             0.283955\n",
       "concavity_se               0.071872\n",
       "concave points_se          0.389847\n",
       "symmetry_se                0.184120\n",
       "fractal_dimension_se       0.127006\n",
       "radius_worst               0.266376\n",
       "texture_worst              0.317112\n",
       "perimeter_worst            0.247496\n",
       "area_worst                 0.148378\n",
       "smoothness_worst           0.483590\n",
       "compactness_worst          0.197677\n",
       "concavity_worst            0.359744\n",
       "concave points_worst       0.371668\n",
       "symmetry_worst             0.260116\n",
       "fractal_dimension_worst    0.170731\n",
       "Name: 4189, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15518954990770978"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_t_data[lab['labels'] == 1].mode().iloc[0]['radius_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(norm_t_data.iloc[2].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "radius_mean                0.601496\n",
       "texture_mean               0.108218\n",
       "perimeter_mean             0.375786\n",
       "area_mean                  0.246872\n",
       "smoothness_mean            0.263519\n",
       "compactness_mean           0.131648\n",
       "concavity_mean             0.138051\n",
       "concave points_mean        0.156909\n",
       "symmetry_mean              0.151010\n",
       "fractal_dimension_mean     0.111626\n",
       "radius_se                  0.036900\n",
       "texture_se                 0.000575\n",
       "perimeter_se               0.036187\n",
       "area_se                    0.024651\n",
       "smoothness_se              0.087636\n",
       "compactness_se             0.075916\n",
       "concavity_se               0.046490\n",
       "concave points_se          0.139667\n",
       "symmetry_se                0.023316\n",
       "fractal_dimension_se       0.026298\n",
       "radius_worst               0.336179\n",
       "texture_worst              0.103945\n",
       "perimeter_worst            0.315205\n",
       "area_worst                 0.183715\n",
       "smoothness_worst           0.336987\n",
       "compactness_worst          0.185610\n",
       "concavity_worst            0.236581\n",
       "concave points_worst       0.355670\n",
       "symmetry_worst             0.148827\n",
       "fractal_dimension_worst    0.129214\n",
       "Name: 457, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "radius_mean                0.244476\n",
       "texture_mean               0.277469\n",
       "perimeter_mean             0.236925\n",
       "area_mean                  0.135436\n",
       "smoothness_mean            0.359733\n",
       "compactness_mean           0.186199\n",
       "concavity_mean             0.107914\n",
       "concave points_mean        0.127820\n",
       "symmetry_mean              0.344374\n",
       "fractal_dimension_mean     0.271849\n",
       "radius_se                  0.062496\n",
       "texture_se                 0.190103\n",
       "perimeter_se               0.058584\n",
       "area_se                    0.026771\n",
       "smoothness_se              0.186385\n",
       "compactness_se             0.144097\n",
       "concavity_se               0.065648\n",
       "concave points_se          0.186733\n",
       "symmetry_se                0.178728\n",
       "fractal_dimension_se       0.094705\n",
       "radius_worst               0.193874\n",
       "texture_worst              0.306372\n",
       "perimeter_worst            0.182260\n",
       "area_worst                 0.091845\n",
       "smoothness_worst           0.355210\n",
       "compactness_worst          0.150753\n",
       "concavity_worst            0.132778\n",
       "concave points_worst       0.255822\n",
       "symmetry_worst             0.224218\n",
       "fractal_dimension_worst    0.160056\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_t_data.loc[lab['labels'] == 1].mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "radius_mean                0.601496\n",
       "texture_mean               0.390260\n",
       "perimeter_mean             0.595743\n",
       "area_mean                  0.449417\n",
       "smoothness_mean            0.514309\n",
       "compactness_mean           0.431017\n",
       "concavity_mean             0.462512\n",
       "concave points_mean        0.635686\n",
       "symmetry_mean              0.509596\n",
       "fractal_dimension_mean     0.211247\n",
       "radius_se                  0.229622\n",
       "texture_se                 0.094303\n",
       "perimeter_se               0.180370\n",
       "area_se                    0.162922\n",
       "smoothness_se              0.150831\n",
       "compactness_se             0.283955\n",
       "concavity_se               0.096768\n",
       "concave points_se          0.389847\n",
       "symmetry_se                0.205690\n",
       "fractal_dimension_se       0.127006\n",
       "radius_worst               0.556386\n",
       "texture_worst              0.360075\n",
       "perimeter_worst            0.508442\n",
       "area_worst                 0.374508\n",
       "smoothness_worst           0.483590\n",
       "compactness_worst          0.385375\n",
       "concavity_worst            0.359744\n",
       "concave points_worst       0.835052\n",
       "symmetry_worst             0.403706\n",
       "fractal_dimension_worst    0.213433\n",
       "Name: 2, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_t_data.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "radius_mean                0.601496\n",
       "texture_mean               0.108218\n",
       "perimeter_mean             0.375786\n",
       "area_mean                  0.246872\n",
       "smoothness_mean            0.263519\n",
       "compactness_mean           0.131648\n",
       "concavity_mean             0.138051\n",
       "concave points_mean        0.156909\n",
       "symmetry_mean              0.151010\n",
       "fractal_dimension_mean     0.111626\n",
       "radius_se                  0.036900\n",
       "texture_se                 0.000575\n",
       "perimeter_se               0.036187\n",
       "area_se                    0.024651\n",
       "smoothness_se              0.087636\n",
       "compactness_se             0.075916\n",
       "concavity_se               0.046490\n",
       "concave points_se          0.139667\n",
       "symmetry_se                0.023316\n",
       "fractal_dimension_se       0.026298\n",
       "radius_worst               0.336179\n",
       "texture_worst              0.103945\n",
       "perimeter_worst            0.315205\n",
       "area_worst                 0.183715\n",
       "smoothness_worst           0.336987\n",
       "compactness_worst          0.185610\n",
       "concavity_worst            0.236581\n",
       "concave points_worst       0.355670\n",
       "symmetry_worst             0.148827\n",
       "fractal_dimension_worst    0.129214\n",
       "Name: 457, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.192638</td>\n",
       "      <td>-6.931324</td>\n",
       "      <td>-4.133661</td>\n",
       "      <td>-5.093168</td>\n",
       "      <td>-13.220222</td>\n",
       "      <td>-8.030053</td>\n",
       "      <td>-4.302013</td>\n",
       "      <td>-3.949061</td>\n",
       "      <td>-7.344799</td>\n",
       "      <td>96.839283</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.689295</td>\n",
       "      <td>-4.412554</td>\n",
       "      <td>-3.790188</td>\n",
       "      <td>-5.118963</td>\n",
       "      <td>-9.970644</td>\n",
       "      <td>-13.545155</td>\n",
       "      <td>-5.491863</td>\n",
       "      <td>-3.387924</td>\n",
       "      <td>-18.229497</td>\n",
       "      <td>-14.836517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0    -4.192638     -6.931324       -4.133661  -5.093168       -13.220222   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0         -8.030053       -4.302013            -3.949061      -7.344799   \n",
       "\n",
       "   fractal_dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0               96.839283  ...     -3.689295      -4.412554        -3.790188   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0   -5.118963         -9.970644         -13.545155        -5.491863   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0             -3.387924      -18.229497               -14.836517  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l0_norm(vector):\n",
    "    \"\"\"\n",
    "    Calculate the L0 norm of a vector, which is the count of non-zero elements in the vector.\n",
    "\n",
    "    Args:\n",
    "    - vector: The input vector (list or array).\n",
    "\n",
    "    Returns:\n",
    "    - The L0 norm of the vector (count of non-zero elements).\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for element in vector:\n",
    "        if element != 0:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(norm_t_data, lab, test_size=0.3, random_state=42)  # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.64077087\n",
      "Iteration 2, loss = 0.53083030\n",
      "Iteration 3, loss = 0.42406778\n",
      "Iteration 4, loss = 0.35559745\n",
      "Iteration 5, loss = 0.31591907\n",
      "Iteration 6, loss = 0.28053929\n",
      "Iteration 7, loss = 0.25997796\n",
      "Iteration 8, loss = 0.24583135\n",
      "Iteration 9, loss = 0.23095861\n",
      "Iteration 10, loss = 0.21229214\n",
      "Iteration 11, loss = 0.18901531\n",
      "Iteration 12, loss = 0.17805540\n",
      "Iteration 13, loss = 0.16492963\n",
      "Iteration 14, loss = 0.15340346\n",
      "Iteration 15, loss = 0.14085805\n",
      "Iteration 16, loss = 0.12920563\n",
      "Iteration 17, loss = 0.12152019\n",
      "Iteration 18, loss = 0.11406115\n",
      "Iteration 19, loss = 0.10554150\n",
      "Iteration 20, loss = 0.10055059\n",
      "Iteration 21, loss = 0.09590339\n",
      "Iteration 22, loss = 0.09356881\n",
      "Iteration 23, loss = 0.08469624\n",
      "Iteration 24, loss = 0.08436484\n",
      "Iteration 25, loss = 0.08340997\n",
      "Iteration 26, loss = 0.07402309\n",
      "Iteration 27, loss = 0.07909781\n",
      "Iteration 28, loss = 0.07107394\n",
      "Iteration 29, loss = 0.07082861\n",
      "Iteration 30, loss = 0.06571904\n",
      "Iteration 31, loss = 0.06613034\n",
      "Iteration 32, loss = 0.06625575\n",
      "Iteration 33, loss = 0.06188739\n",
      "Iteration 34, loss = 0.05936886\n",
      "Iteration 35, loss = 0.06183667\n",
      "Iteration 36, loss = 0.05828160\n",
      "Iteration 37, loss = 0.05576399\n",
      "Iteration 38, loss = 0.05549913\n",
      "Iteration 39, loss = 0.05686136\n",
      "Iteration 40, loss = 0.05304459\n",
      "Iteration 41, loss = 0.05590075\n",
      "Iteration 42, loss = 0.05111340\n",
      "Iteration 43, loss = 0.05024694\n",
      "Iteration 44, loss = 0.05207838\n",
      "Iteration 45, loss = 0.06007129\n",
      "Iteration 46, loss = 0.05834072\n",
      "Iteration 47, loss = 0.05041280\n",
      "Iteration 48, loss = 0.04859115\n",
      "Iteration 49, loss = 0.04928806\n",
      "Iteration 50, loss = 0.05937130\n",
      "Iteration 51, loss = 0.04700039\n",
      "Iteration 52, loss = 0.05685677\n",
      "Iteration 53, loss = 0.04607721\n",
      "Iteration 54, loss = 0.04712192\n",
      "Iteration 55, loss = 0.04445666\n",
      "Iteration 56, loss = 0.04230869\n",
      "Iteration 57, loss = 0.04511420\n",
      "Iteration 58, loss = 0.04014764\n",
      "Iteration 59, loss = 0.03958598\n",
      "Iteration 60, loss = 0.04106825\n",
      "Iteration 61, loss = 0.04254454\n",
      "Iteration 62, loss = 0.04754968\n",
      "Iteration 63, loss = 0.04177774\n",
      "Iteration 64, loss = 0.03674120\n",
      "Iteration 65, loss = 0.04045934\n",
      "Iteration 66, loss = 0.04239291\n",
      "Iteration 67, loss = 0.06113551\n",
      "Iteration 68, loss = 0.05866217\n",
      "Iteration 69, loss = 0.05407478\n",
      "Iteration 70, loss = 0.04435727\n",
      "Iteration 71, loss = 0.04869743\n",
      "Iteration 72, loss = 0.03906532\n",
      "Iteration 73, loss = 0.03587053\n",
      "Iteration 74, loss = 0.03784213\n",
      "Iteration 75, loss = 0.04086511\n",
      "Iteration 76, loss = 0.03334720\n",
      "Iteration 77, loss = 0.04034416\n",
      "Iteration 78, loss = 0.03344562\n",
      "Iteration 79, loss = 0.03422165\n",
      "Iteration 80, loss = 0.03772591\n",
      "Iteration 81, loss = 0.04003025\n",
      "Iteration 82, loss = 0.03076690\n",
      "Iteration 83, loss = 0.04081754\n",
      "Iteration 84, loss = 0.05260544\n",
      "Iteration 85, loss = 0.06898436\n",
      "Iteration 86, loss = 0.05281028\n",
      "Iteration 87, loss = 0.04958918\n",
      "Iteration 88, loss = 0.06744523\n",
      "Iteration 89, loss = 0.03750803\n",
      "Iteration 90, loss = 0.05699941\n",
      "Iteration 91, loss = 0.06190218\n",
      "Iteration 92, loss = 0.03630375\n",
      "Iteration 93, loss = 0.05302807\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amade\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(6, 5), learning_rate_init=0.05,\n",
       "              random_state=42, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(6, 5), learning_rate_init=0.05,\n",
       "              random_state=42, verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(6, 5), learning_rate_init=0.05,\n",
       "              random_state=42, verbose=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(hidden_layer_sizes=(6,5),\n",
    "                    random_state=42,\n",
    "                    verbose=True,\n",
    "                    learning_rate_init=0.05)\n",
    "\n",
    "# Fit data onto the model\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 3.13843157e-18],\n",
       "       [1.00000000e+00, 9.09092192e-11],\n",
       "       [1.00000000e+00, 4.34196525e-16],\n",
       "       ...,\n",
       "       [9.99993995e-01, 6.00511964e-06],\n",
       "       [1.00000000e+00, 3.84944956e-22],\n",
       "       [1.06250416e-02, 9.89374958e-01]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(norm_t_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\amade\\Documents\\GitHub\\Explainable-AI\\Counterfactual Explanations\\CLEAR\\clear_example_for_lvq_models.ipynb Cell 26\u001b[0m line \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/amade/Documents/GitHub/Explainable-AI/Counterfactual%20Explanations/CLEAR/clear_example_for_lvq_models.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m new_explainer \u001b[39m=\u001b[39m CLEAR1(clf, \u001b[39m100\u001b[39m,backend \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39msklearn\u001b[39m\u001b[39m'\u001b[39m, synthetic_generator_scheme\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPerturbation\u001b[39m\u001b[39m'\u001b[39m,  classification_threshold \u001b[39m=\u001b[39m \u001b[39m0.90\u001b[39m, number_of_CFEs \u001b[39m=\u001b[39m \u001b[39m200\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/amade/Documents/GitHub/Explainable-AI/Counterfactual%20Explanations/CLEAR/clear_example_for_lvq_models.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m new_explainer\u001b[39m.\u001b[39mfit(norm_t_data, lab)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/amade/Documents/GitHub/Explainable-AI/Counterfactual%20Explanations/CLEAR/clear_example_for_lvq_models.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m cf, es_cf \u001b[39m=\u001b[39m new_explainer\u001b[39m.\u001b[39;49mgenerate_counterfactual(norm_t_data\u001b[39m.\u001b[39;49miloc[\u001b[39m0\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\Users\\amade\\Documents\\GitHub\\Explainable-AI\\Counterfactual Explanations\\CLEAR\\clear.py:678\u001b[0m, in \u001b[0;36mCLEAR1.generate_counterfactual\u001b[1;34m(self, unit, target_class)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39m# unit_class = self.model.predict(unit, self.prototypes, proto_labels)\u001b[39;00m\n\u001b[0;32m    677\u001b[0m counterfactual_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwachter_search(unit, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_class)\n\u001b[1;32m--> 678\u001b[0m estimations \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimated_b_counterfactual(unit,  \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_class)\n\u001b[0;32m    679\u001b[0m FEs \u001b[39m=\u001b[39m []\n\u001b[0;32m    680\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(estimations)):\n",
      "File \u001b[1;32mc:\\Users\\amade\\Documents\\GitHub\\Explainable-AI\\Counterfactual Explanations\\CLEAR\\clear.py:612\u001b[0m, in \u001b[0;36mCLEAR1.estimated_b_counterfactual\u001b[1;34m(self, unit, target_class)\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mestimated_b_counterfactual\u001b[39m(\u001b[39mself\u001b[39m, unit, target_class):\n\u001b[0;32m    611\u001b[0m     counterfactual_list \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwachter_search(unit,  target_class))\n\u001b[1;32m--> 612\u001b[0m     w \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfind_weights(unit, target_class)\n\u001b[0;32m    614\u001b[0m     estimate \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((counterfactual_list\u001b[39m.\u001b[39mshape))\n\u001b[0;32m    615\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(counterfactual_list\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[0;32m    616\u001b[0m         \u001b[39m#b_counter = b_counterfactual.copy()\u001b[39;00m\n\u001b[0;32m    617\u001b[0m         \u001b[39m#b_counter = b_counter.reshape((1,counterfactual_list.shape[1]))\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\amade\\Documents\\GitHub\\Explainable-AI\\Counterfactual Explanations\\CLEAR\\clear.py:529\u001b[0m, in \u001b[0;36mCLEAR1.find_weights\u001b[1;34m(self, unit, target_class)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_weights\u001b[39m(\u001b[39mself\u001b[39m, unit, target_class):\n\u001b[1;32m--> 529\u001b[0m     balenced_data, balanced_labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mBalanced_Neighbourhood(unit,  target_class)\n\u001b[0;32m    530\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mr \u001b[39m==\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    531\u001b[0m         \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinear_model\u001b[39;00m \u001b[39mimport\u001b[39;00m LogisticRegression\n",
      "File \u001b[1;32mc:\\Users\\amade\\Documents\\GitHub\\Explainable-AI\\Counterfactual Explanations\\CLEAR\\clear.py:437\u001b[0m, in \u001b[0;36mCLEAR1.Balanced_Neighbourhood\u001b[1;34m(self, unit, target_class)\u001b[0m\n\u001b[0;32m    434\u001b[0m         distances\u001b[39m.\u001b[39mappend([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcat_con_dist(unit, cut[j]), j])\n\u001b[0;32m    435\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 437\u001b[0m         distances\u001b[39m.\u001b[39mappend([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mMAD(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_data, unit, cut[j]), j])\n\u001b[0;32m    438\u001b[0m dist \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(distances)\u001b[39m.\u001b[39mreshape((\u001b[39mlen\u001b[39m(cut), \u001b[39m2\u001b[39m))\n\u001b[0;32m    440\u001b[0m sorted_distances \u001b[39m=\u001b[39m dist[dist[:,\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39margsort()]\n",
      "File \u001b[1;32mc:\\Users\\amade\\Documents\\GitHub\\Explainable-AI\\Counterfactual Explanations\\CLEAR\\clear.py:288\u001b[0m, in \u001b[0;36mCLEAR1.MAD\u001b[1;34m(self, data, a, b)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mMAD\u001b[39m (\u001b[39mself\u001b[39m, data, a, b):\n\u001b[1;32m--> 288\u001b[0m     \u001b[39mreturn\u001b[39;00m ((\u001b[39mabs\u001b[39m(a \u001b[39m-\u001b[39m b))\u001b[39m/\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mMean_absolute_deviation(data))\u001b[39m.\u001b[39msum()\n",
      "File \u001b[1;32mc:\\Users\\amade\\Documents\\GitHub\\Explainable-AI\\Counterfactual Explanations\\CLEAR\\clear.py:270\u001b[0m, in \u001b[0;36mCLEAR1.Mean_absolute_deviation\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mMean_absolute_deviation\u001b[39m(\u001b[39mself\u001b[39m, data):\n\u001b[1;32m--> 270\u001b[0m     feature_medians \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mmedian(data, axis \u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m)\n\u001b[0;32m    271\u001b[0m     diff \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mabsolute(data \u001b[39m-\u001b[39m feature_medians)\n\u001b[0;32m    272\u001b[0m     MAD \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmedian(diff, axis \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mmedian\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\lib\\function_base.py:3816\u001b[0m, in \u001b[0;36mmedian\u001b[1;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[0;32m   3734\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_median_dispatcher)\n\u001b[0;32m   3735\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmedian\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, overwrite_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m   3736\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   3737\u001b[0m \u001b[39m    Compute the median along the specified axis.\u001b[39;00m\n\u001b[0;32m   3738\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3814\u001b[0m \n\u001b[0;32m   3815\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3816\u001b[0m     r, k \u001b[39m=\u001b[39m _ureduce(a, func\u001b[39m=\u001b[39;49m_median, axis\u001b[39m=\u001b[39;49maxis, out\u001b[39m=\u001b[39;49mout,\n\u001b[0;32m   3817\u001b[0m                     overwrite_input\u001b[39m=\u001b[39;49moverwrite_input)\n\u001b[0;32m   3818\u001b[0m     \u001b[39mif\u001b[39;00m keepdims:\n\u001b[0;32m   3819\u001b[0m         \u001b[39mreturn\u001b[39;00m r\u001b[39m.\u001b[39mreshape(k)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\lib\\function_base.py:3725\u001b[0m, in \u001b[0;36m_ureduce\u001b[1;34m(a, func, **kwargs)\u001b[0m\n\u001b[0;32m   3722\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3723\u001b[0m     keepdim \u001b[39m=\u001b[39m (\u001b[39m1\u001b[39m,) \u001b[39m*\u001b[39m a\u001b[39m.\u001b[39mndim\n\u001b[1;32m-> 3725\u001b[0m r \u001b[39m=\u001b[39m func(a, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   3726\u001b[0m \u001b[39mreturn\u001b[39;00m r, keepdim\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\lib\\function_base.py:3851\u001b[0m, in \u001b[0;36m_median\u001b[1;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[0;32m   3849\u001b[0m         part \u001b[39m=\u001b[39m a\n\u001b[0;32m   3850\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 3851\u001b[0m     part \u001b[39m=\u001b[39m partition(a, kth, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   3853\u001b[0m \u001b[39mif\u001b[39;00m part\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m ():\n\u001b[0;32m   3854\u001b[0m     \u001b[39m# make 0-D arrays work\u001b[39;00m\n\u001b[0;32m   3855\u001b[0m     \u001b[39mreturn\u001b[39;00m part\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mpartition\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\core\\fromnumeric.py:758\u001b[0m, in \u001b[0;36mpartition\u001b[1;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[0;32m    756\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    757\u001b[0m     a \u001b[39m=\u001b[39m asanyarray(a)\u001b[39m.\u001b[39mcopy(order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mK\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 758\u001b[0m a\u001b[39m.\u001b[39;49mpartition(kth, axis\u001b[39m=\u001b[39;49maxis, kind\u001b[39m=\u001b[39;49mkind, order\u001b[39m=\u001b[39;49morder)\n\u001b[0;32m    759\u001b[0m \u001b[39mreturn\u001b[39;00m a\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "new_explainer = CLEAR1(clf, 100,backend = 'sklearn', synthetic_generator_scheme='Perturbation',  classification_threshold = 0.90, number_of_CFEs = 200)\n",
    "new_explainer.fit(norm_t_data, lab)\n",
    "cf, es_cf = new_explainer.generate_counterfactual(norm_t_data.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.902976</td>\n",
       "      <td>-3.873413</td>\n",
       "      <td>-3.786075</td>\n",
       "      <td>-4.678626</td>\n",
       "      <td>-12.97278</td>\n",
       "      <td>-7.327585</td>\n",
       "      <td>-3.602776</td>\n",
       "      <td>-3.377462</td>\n",
       "      <td>-10.745538</td>\n",
       "      <td>13.882143</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.905837</td>\n",
       "      <td>-4.706701</td>\n",
       "      <td>-4.190503</td>\n",
       "      <td>-5.397041</td>\n",
       "      <td>-10.733194</td>\n",
       "      <td>-10.865245</td>\n",
       "      <td>-6.115272</td>\n",
       "      <td>-3.053883</td>\n",
       "      <td>-646.772391</td>\n",
       "      <td>-23.235719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0    -3.902976     -3.873413       -3.786075  -4.678626        -12.97278   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0         -7.327585       -3.602776            -3.377462     -10.745538   \n",
       "\n",
       "   fractal_dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0               13.882143  ...     -3.905837      -4.706701        -4.190503   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0   -5.397041        -10.733194         -10.865245        -6.115272   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0             -3.053883     -646.772391               -23.235719  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l0_norm(np.array(cf.iloc[0] - norm_t_data.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(es_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5589457336845318\n"
     ]
    }
   ],
   "source": [
    "from density_check import Kernel_obj\n",
    "print(Kernel_obj(np.array(norm_t_data.loc[lab['labels'] == 1])).knn_density(np.array(cf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'A', 10.0),\n",
       " (1, 'A', 20.0),\n",
       " (1, 'A', 30.0),\n",
       " (1, 'B', 10.0),\n",
       " (1, 'B', 20.0),\n",
       " (1, 'B', 30.0),\n",
       " (1, 'C', 10.0),\n",
       " (1, 'C', 20.0),\n",
       " (1, 'C', 30.0),\n",
       " (2, 'A', 10.0),\n",
       " (2, 'A', 20.0),\n",
       " (2, 'A', 30.0),\n",
       " (2, 'B', 10.0),\n",
       " (2, 'B', 20.0),\n",
       " (2, 'B', 30.0),\n",
       " (2, 'C', 10.0),\n",
       " (2, 'C', 20.0),\n",
       " (2, 'C', 30.0),\n",
       " (3, 'A', 10.0),\n",
       " (3, 'A', 20.0),\n",
       " (3, 'A', 30.0),\n",
       " (3, 'B', 10.0),\n",
       " (3, 'B', 20.0),\n",
       " (3, 'B', 30.0),\n",
       " (3, 'C', 10.0),\n",
       " (3, 'C', 20.0),\n",
       " (3, 'C', 30.0)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "def cartesian_product_vectors(vectors):\n",
    "    \"\"\"\n",
    "    Generate the Cartesian product of a set of vectors, assuming all vectors have the same dimension.\n",
    "\n",
    "    Args:\n",
    "    vectors (list of lists or tuples): List of vectors to form the Cartesian product.\n",
    "\n",
    "    Returns:\n",
    "    list of lists: A list of vectors with the same dimension formed by the Cartesian product.\n",
    "    \"\"\"\n",
    "    cartesian_product = product(*vectors)\n",
    "    return list(cartesian_product)\n",
    "\n",
    "# Example usage:\n",
    "vectors = [[1, 2, 3], ['A', 'B', 'C'], [10.0, 20.0, 30.0]]\n",
    "\n",
    "ca = cartesian_product_vectors(vectors)\n",
    "ca\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 'A', 10]\n",
      "[1, 'A', 20]\n",
      "[1, 'B', 10]\n",
      "[1, 'B', 20]\n",
      "[2, 'A', 10]\n",
      "[2, 'A', 20]\n",
      "[2, 'B', 10]\n",
      "[2, 'B', 20]\n"
     ]
    }
   ],
   "source": [
    "def cartesian_product_vectors(vectors):\n",
    "    if not vectors:\n",
    "        return [()]\n",
    "\n",
    "    def recursive_cartesian_product(index):\n",
    "        if index == len(vectors):\n",
    "            return [()]\n",
    "        current_vector = vectors[index]\n",
    "        previous_product = recursive_cartesian_product(index + 1)\n",
    "        result = []\n",
    "        for value in current_vector:\n",
    "            for product in previous_product:\n",
    "                result.append([value] + list(product))\n",
    "        return result\n",
    "\n",
    "    return recursive_cartesian_product(0)\n",
    "\n",
    "# Example usage:\n",
    "vector1 = [1, 2]\n",
    "vector2 = ['A', 'B']\n",
    "vector3 = [10, 20]\n",
    "\n",
    "vectors = [vector1, vector2, vector3]\n",
    "\n",
    "result = cartesian_product_vectors(vectors)\n",
    "\n",
    "for item in result:\n",
    "    print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, -0.07044580372031928, 3.0, 4.0, -0.10064159381957061]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def perturb_vector(vector, num_to_perturb, mean=0, std_dev=1):\n",
    "    \"\"\"\n",
    "    Perturb a vector by replacing a specified number of its values with random samples\n",
    "    from a Gaussian distribution.\n",
    "\n",
    "    Args:\n",
    "    - vector: The input vector (list) to be perturbed.\n",
    "    - num_to_perturb: The number of values to perturb.\n",
    "    - mean: The mean of the Gaussian distribution (default is 0).\n",
    "    - std_dev: The standard deviation of the Gaussian distribution (default is 1).\n",
    "\n",
    "    Returns:\n",
    "    - The perturbed vector with some values replaced by Gaussian samples.\n",
    "    \"\"\"\n",
    "    if num_to_perturb < 0 or num_to_perturb > len(vector):\n",
    "        raise ValueError(\"num_to_perturb should be between 0 and the length of the vector\")\n",
    "\n",
    "    # Create a copy of the input vector to avoid modifying the original\n",
    "    perturbed_vector = vector.copy()\n",
    "\n",
    "    # Choose random indices to perturb\n",
    "    indices_to_perturb = random.sample(range(len(perturbed_vector)), num_to_perturb)\n",
    "\n",
    "    # Perturb the selected indices\n",
    "    for index in indices_to_perturb:\n",
    "        perturbed_vector[index] = np.random.normal(mean, std_dev)\n",
    "\n",
    "    return perturbed_vector\n",
    "\n",
    "# Example usage:\n",
    "original_vector = [1.0, 2.0, 3.0, 4.0, 5.0]\n",
    "num_to_perturb = 2\n",
    "perturbed = perturb_vector(original_vector, num_to_perturb, mean=0, std_dev=0.1)\n",
    "print(perturbed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def synthetic_generator(unit, train_data, training_labels, target_class):\n",
    "    target_points = train_data.loc[training_labels['labels'] == target_class]\n",
    "    lst = []\n",
    "    for i in range(len(unit)):\n",
    "        for j in range(len(unit)):\n",
    "            lst.append(perturb_vector(unit, i+1, mean=0, std_dev=0.1))\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "    return np.array(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = synthetic_generator(norm_t_data.iloc[0], norm_t_data, lab, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[1]\n",
      "[1, 2]\n",
      "[1, 2, 3]\n",
      "[1, 3]\n",
      "[2]\n",
      "[2, 3]\n",
      "[3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[], [1], [1, 2], [1, 2, 3], [1, 3], [2], [2, 3], [3]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_subsets(nums):\n",
    "    def backtrack(start, current_subset):\n",
    "        # Add the current subset to the list of subsets\n",
    "        subsets.append(current_subset[:])\n",
    "        \n",
    "        # Explore all possible options to form subsets\n",
    "        for i in range(start, len(nums)):\n",
    "            current_subset.append(nums[i])\n",
    "            backtrack(i + 1, current_subset)\n",
    "            current_subset.pop()\n",
    "\n",
    "    subsets = []\n",
    "    backtrack(0, [])\n",
    "    return subsets\n",
    "\n",
    "# Example usage:\n",
    "input_set = [1, 2, 3]\n",
    "all_subsets = generate_subsets(input_set)\n",
    "for subset in all_subsets:\n",
    "    print(subset)\n",
    "all_subsets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l0_norm(vector):\n",
    "    \"\"\"\n",
    "    Calculate the L0 norm of a vector, which is the count of non-zero elements in the vector.\n",
    "\n",
    "    Args:\n",
    "    - vector: The input vector (list or array).\n",
    "\n",
    "    Returns:\n",
    "    - The L0 norm of the vector (count of non-zero elements).\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for element in vector:\n",
    "        if element != 0:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Age': [25, 30, 22, 35, 28, 32, 19, 40, 27, 23],\n",
    "    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Male', 'Female', 'Male'],\n",
    "    'Favorite Color': ['Blue', 'Red', 'Green', 'Blue', 'Red', 'Green', 'Blue', 'Green', 'Red', 'Blue'],\n",
    "    'Salary': [50000.0, 60000.0, 45000.0, 75000.0, 55000.0, 68000.0, 42000.0, 80000.0, 63000.0, 47000.0],\n",
    "    'Label': [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]  # Example labels (0 and 1)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform one-hot encoding for 'Gender' and 'Favorite Color'\n",
    "df = pd.get_dummies(df, columns=['Gender', 'Favorite Color'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['Label']\n",
    "labe = pd.DataFrame(np.array(labels), columns=['labels'])\n",
    "df.drop(['Label'], axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, labe, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 15.44738673\n",
      "Iteration 2, loss = 15.44737509\n",
      "Iteration 3, loss = 15.44736601\n",
      "Iteration 4, loss = 15.44735940\n",
      "Iteration 5, loss = 15.44735470\n",
      "Iteration 6, loss = 0.89220860\n",
      "Iteration 7, loss = 0.90246690\n",
      "Iteration 8, loss = 2.06987933\n",
      "Iteration 9, loss = 0.91683860\n",
      "Iteration 10, loss = 0.92161599\n",
      "Iteration 11, loss = 0.92363420\n",
      "Iteration 12, loss = 0.92334033\n",
      "Iteration 13, loss = 15.44735540\n",
      "Iteration 14, loss = 0.92167429\n",
      "Iteration 15, loss = 0.92034532\n",
      "Iteration 16, loss = 0.91740606\n",
      "Iteration 17, loss = 0.91310328\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amade\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(6, 5), learning_rate_init=0.05,\n",
       "              random_state=42, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(6, 5), learning_rate_init=0.05,\n",
       "              random_state=42, verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(6, 5), learning_rate_init=0.05,\n",
       "              random_state=42, verbose=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_explainer = CLEAR1(clf, 100,backend = 'sklearn', synthetic_generator_scheme='Gaussian',  classification_threshold = 0.90,cat_cols= ['Gender_Female', 'Gender_Male', 'Favorite Color_Blue', 'Favorite Color_Green', 'Favorite Color_Red'], number_of_CFEs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.5e+01, 5.0e+04, 0.0e+00, 1.0e+00, 1.0e+00, 0.0e+00, 0.0e+00])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(df.iloc[0])#.reshape((1, df.shape[1])), columns =df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_explainer.fit(df, labe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no numerical column specified\n"
     ]
    }
   ],
   "source": [
    "a, b = new_explainer.synthetic_generator(df, labe,df.iloc[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Favorite Color_Blue</th>\n",
       "      <th>Favorite Color_Green</th>\n",
       "      <th>Favorite Color_Red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>55000.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>63000.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28.923088</td>\n",
       "      <td>42158.501052</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28.263952</td>\n",
       "      <td>59180.584564</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20.111462</td>\n",
       "      <td>48878.558032</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25.407193</td>\n",
       "      <td>43771.635532</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21.467207</td>\n",
       "      <td>63231.415234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>27.093759</td>\n",
       "      <td>48909.229441</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>35.005275</td>\n",
       "      <td>53570.707180</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18.749207</td>\n",
       "      <td>45137.649374</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>26.018862</td>\n",
       "      <td>58066.161420</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>24.634711</td>\n",
       "      <td>37956.317834</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>25.549243</td>\n",
       "      <td>55345.056717</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>27.482838</td>\n",
       "      <td>41039.284710</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>68000.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>80000.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>47000.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>32.701553</td>\n",
       "      <td>66231.557887</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>30.352334</td>\n",
       "      <td>78135.156618</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>30.693978</td>\n",
       "      <td>55596.468103</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25.572863</td>\n",
       "      <td>56161.113312</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>31.118394</td>\n",
       "      <td>80520.137350</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>32.745896</td>\n",
       "      <td>61068.455113</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>38.590001</td>\n",
       "      <td>67901.851646</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>31.188930</td>\n",
       "      <td>64273.898828</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>21.154573</td>\n",
       "      <td>63766.782529</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>38.319264</td>\n",
       "      <td>57629.540689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>29.877221</td>\n",
       "      <td>35792.037136</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>38.962484</td>\n",
       "      <td>84369.770070</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age        Salary  Gender_Female  Gender_Male  Favorite Color_Blue  \\\n",
       "0   25.000000  50000.000000              0            1                    1   \n",
       "1   22.000000  45000.000000              0            1                    0   \n",
       "2   28.000000  55000.000000              0            1                    0   \n",
       "3   19.000000  42000.000000              0            1                    1   \n",
       "4   27.000000  63000.000000              1            0                    0   \n",
       "5   28.923088  42158.501052              0            1                    0   \n",
       "6   28.263952  59180.584564              0            1                    0   \n",
       "7   20.111462  48878.558032              1            1                    1   \n",
       "8   25.407193  43771.635532              1            1                    1   \n",
       "9   21.467207  63231.415234              0            0                    1   \n",
       "10  27.093759  48909.229441              0            1                    0   \n",
       "11  35.005275  53570.707180              0            1                    1   \n",
       "12  18.749207  45137.649374              0            0                    0   \n",
       "13  26.018862  58066.161420              1            1                    1   \n",
       "14  24.634711  37956.317834              0            0                    1   \n",
       "15  25.549243  55345.056717              0            1                    1   \n",
       "16  27.482838  41039.284710              0            1                    0   \n",
       "17  30.000000  60000.000000              1            0                    0   \n",
       "18  35.000000  75000.000000              1            0                    1   \n",
       "19  32.000000  68000.000000              1            0                    0   \n",
       "20  40.000000  80000.000000              0            1                    0   \n",
       "21  23.000000  47000.000000              0            1                    1   \n",
       "22  32.701553  66231.557887              0            1                    0   \n",
       "23  30.352334  78135.156618              0            1                    1   \n",
       "24  30.693978  55596.468103              1            0                    1   \n",
       "25  25.572863  56161.113312              1            1                    1   \n",
       "26  31.118394  80520.137350              1            1                    0   \n",
       "27  32.745896  61068.455113              1            0                    0   \n",
       "28  38.590001  67901.851646              0            0                    1   \n",
       "29  31.188930  64273.898828              1            1                    0   \n",
       "30  21.154573  63766.782529              1            0                    1   \n",
       "31  38.319264  57629.540689              0            0                    0   \n",
       "32  29.877221  35792.037136              1            1                    0   \n",
       "33  38.962484  84369.770070              0            1                    0   \n",
       "\n",
       "    Favorite Color_Green  Favorite Color_Red  \n",
       "0                      0                   0  \n",
       "1                      1                   0  \n",
       "2                      0                   1  \n",
       "3                      0                   0  \n",
       "4                      0                   1  \n",
       "5                      0                   0  \n",
       "6                      1                   1  \n",
       "7                      0                   1  \n",
       "8                      0                   0  \n",
       "9                      0                   0  \n",
       "10                     0                   1  \n",
       "11                     0                   1  \n",
       "12                     0                   0  \n",
       "13                     1                   1  \n",
       "14                     0                   0  \n",
       "15                     1                   0  \n",
       "16                     0                   0  \n",
       "17                     0                   1  \n",
       "18                     0                   0  \n",
       "19                     1                   0  \n",
       "20                     1                   0  \n",
       "21                     0                   0  \n",
       "22                     1                   0  \n",
       "23                     1                   0  \n",
       "24                     1                   0  \n",
       "25                     1                   0  \n",
       "26                     0                   0  \n",
       "27                     1                   0  \n",
       "28                     0                   1  \n",
       "29                     1                   0  \n",
       "30                     0                   0  \n",
       "31                     0                   0  \n",
       "32                     0                   0  \n",
       "33                     0                   1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no numerical column specified\n",
      "no numerical column specified\n",
      "no numerical column specified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amade\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\amade\\Documents\\GitHub\\Explainable-AI\\Counterfactual Explanations\\CLEAR\\clear_example_for_lvq_models.ipynb Cell 46\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/amade/Documents/GitHub/Explainable-AI/Counterfactual%20Explanations/CLEAR/clear_example_for_lvq_models.ipynb#X63sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m new_explainer\u001b[39m.\u001b[39;49mgenerate_counterfactual(df\u001b[39m.\u001b[39;49miloc[\u001b[39m5\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\Users\\amade\\Documents\\GitHub\\Explainable-AI\\Counterfactual Explanations\\CLEAR\\clear.py:597\u001b[0m, in \u001b[0;36mCLEAR1.generate_counterfactual\u001b[1;34m(self, unit, target_class)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[39m# unit_class = self.model.predict(unit, self.prototypes, proto_labels)\u001b[39;00m\n\u001b[0;32m    596\u001b[0m counterfactual_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwachter_search(unit, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_class)\n\u001b[1;32m--> 597\u001b[0m estimations \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimated_b_counterfactual(unit,  \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_class)\n\u001b[0;32m    598\u001b[0m FEs \u001b[39m=\u001b[39m []\n\u001b[0;32m    599\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(estimations)):\n",
      "File \u001b[1;32mc:\\Users\\amade\\Documents\\GitHub\\Explainable-AI\\Counterfactual Explanations\\CLEAR\\clear.py:531\u001b[0m, in \u001b[0;36mCLEAR1.estimated_b_counterfactual\u001b[1;34m(self, unit, target_class)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mestimated_b_counterfactual\u001b[39m(\u001b[39mself\u001b[39m, unit, target_class):\n\u001b[0;32m    530\u001b[0m     counterfactual_list \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwachter_search(unit,  target_class))\n\u001b[1;32m--> 531\u001b[0m     w \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfind_weights(unit, target_class)\n\u001b[0;32m    533\u001b[0m     estimate \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((counterfactual_list\u001b[39m.\u001b[39mshape))\n\u001b[0;32m    534\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(counterfactual_list\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[0;32m    535\u001b[0m         \u001b[39m#b_counter = b_counterfactual.copy()\u001b[39;00m\n\u001b[0;32m    536\u001b[0m         \u001b[39m#b_counter = b_counter.reshape((1,counterfactual_list.shape[1]))\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\amade\\Documents\\GitHub\\Explainable-AI\\Counterfactual Explanations\\CLEAR\\clear.py:458\u001b[0m, in \u001b[0;36mCLEAR1.find_weights\u001b[1;34m(self, unit, target_class)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[39mwhile\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_runs:\n\u001b[0;32m    457\u001b[0m     n \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 458\u001b[0m     log_model\u001b[39m.\u001b[39;49mfit(x_train, y_train)\n\u001b[0;32m    459\u001b[0m     y_pred \u001b[39m=\u001b[39m log_model\u001b[39m.\u001b[39mpredict(x_test)\n\u001b[0;32m    460\u001b[0m     acc \u001b[39m=\u001b[39m accuracy_score(y_test, y_pred)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1183\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1181\u001b[0m classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\n\u001b[0;32m   1182\u001b[0m \u001b[39mif\u001b[39;00m n_classes \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m-> 1183\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1184\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis solver needs samples of at least 2 classes\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1185\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m in the data, but the data contains only one\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1186\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m class: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1187\u001b[0m         \u001b[39m%\u001b[39m classes_[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1188\u001b[0m     )\n\u001b[0;32m   1190\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m   1191\u001b[0m     n_classes \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 1"
     ]
    }
   ],
   "source": [
    "new_explainer.generate_counterfactual(df.iloc[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels\n",
       "0       0\n",
       "1       1\n",
       "2       0\n",
       "3       1\n",
       "4       0\n",
       "5       1\n",
       "6       0\n",
       "7       1\n",
       "8       0\n",
       "9       1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
