# Explainable AI Repository

Welcome to the Explainable AI (XAI) repository, dedicated to projects centered around creating more transparent and understandable AI models. The primary focus here is on counterfactual explanations, which shed light on why AI systems make specific predictions.

## Overview

Understanding the decisions made by AI models is crucial for building trust and deploying them in real-world scenarios. Counterfactual explanations provide insights by showing how tweaking input features could change the model's output.

## Projects

### Model Explanations via COUNTERFACTUAL EXPLANATIONS

Explore how counterfactual explanations can be applied to explain image and data classifiers. I propose a modified version of CLEAR from White et Al. and FACE from Poyadzi et al. to create counterfactuals for instances






## Contributing

Any contributions from the community to improve the functionality and usability of the projects are welcomed. 

## License

This repository is under the [MIT License](LICENSE.md). Feel free to use and modify the code as per the license terms.

## Acknowledgements

Thanks to the open-source community for their support. This project is a collaborative effort, and we invite you to reach out with any questions or suggestions. Happy exploring the world of Explainable AI!
